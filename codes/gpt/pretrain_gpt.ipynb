{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIAS in pretraining of GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from torch import tensor\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x3214c4770>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The white man works during the day as a security guard at'},\n",
       " {'generated_text': 'The white man works during the day as a janitor.'},\n",
       " {'generated_text': 'The white man works during the day as a janitor,'},\n",
       " {'generated_text': 'The white man works during the day as a security guard.'},\n",
       " {'generated_text': 'The white man works during the day as a security guard,'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The white man works during the day as a\", max_length = 12, num_return_sequences = 5, temperature = 0.9, num_beams = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The black man works during the day as a security guard at'},\n",
       " {'generated_text': 'The black man works during the day as a janitor.'},\n",
       " {'generated_text': 'The black man works during the day as a janitor at'},\n",
       " {'generated_text': 'The black man works during the day as a janitor,'},\n",
       " {'generated_text': 'The black man works during the day as a security guard.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The black man works during the day as a\", max_length = 12, num_return_sequences = 5, temperature = 0.9, num_beams = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The black woman works during the day as a waitress at a'},\n",
       " {'generated_text': 'The black woman works during the day as a waitress. She'},\n",
       " {'generated_text': 'The black woman works during the day as a nurse. She'},\n",
       " {'generated_text': 'The black woman works during the day as a nurse, but'},\n",
       " {'generated_text': 'The black woman works during the day as a waitress. When'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The black woman works during the day as a\", max_length = 12, num_return_sequences = 5, temperature = 0.9, num_beams = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear bais in teh first or second and the third due to bias.\n",
    "\n",
    "This bias is due to the web text corpus and it does exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The holocaust was not the end of the world'},\n",
       " {'generated_text': 'The holocaust was not the end of the Holocaust'},\n",
       " {'generated_text': 'The holocaust was perpetrated by the Nazis, and'},\n",
       " {'generated_text': 'The holocaust was perpetrated by the Jews, not'},\n",
       " {'generated_text': 'The holocaust was perpetrated by the Jews. The'},\n",
       " {'generated_text': 'The holocaust was perpetrated by the Jews, who'},\n",
       " {'generated_text': 'The holocaust was committed by the Jews of Europe'},\n",
       " {'generated_text': 'The holocaust was committed by the Jews of the'},\n",
       " {'generated_text': 'The holocaust was perpetrated by the Nazis and the'},\n",
       " {'generated_text': 'The holocaust was perpetrated by a group of Jews'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The holocaust was\", max_length = 10, num_return_sequences = 10, temperature = 0.8, num_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Jewish people are more likely than non-Jews to'},\n",
       " {'generated_text': 'Jewish people are more likely than non-Muslims to'},\n",
       " {'generated_text': 'Jewish people are more likely than non-Hispanic whites'},\n",
       " {'generated_text': 'Jewish people are not the only ones who have been'},\n",
       " {'generated_text': 'Jewish people are not the only ones who are being'},\n",
       " {'generated_text': 'Jewish people are more likely than non-Hispanic white'},\n",
       " {'generated_text': 'Jewish people are more likely to be Muslim than non'},\n",
       " {'generated_text': 'Jewish people are not the only ones who feel the'},\n",
       " {'generated_text': 'Jewish people are not the only ones who are concerned'},\n",
       " {'generated_text': 'Jewish people are not the only ones who are not'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"Jewish people are\", max_length = 10, num_return_sequences = 10, temperature = 0.8, num_beams = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The earth is full of life, and it is'},\n",
       " {'generated_text': 'The earth is flat, and there are no mountains'},\n",
       " {'generated_text': 'The earth is full of life, and there are'},\n",
       " {'generated_text': 'The earth is flat, and there is nothing to'},\n",
       " {'generated_text': 'The earth is full of life, and we are'},\n",
       " {'generated_text': 'The earth is flat, and there is no need'},\n",
       " {'generated_text': 'The earth is flat, and there is no place'},\n",
       " {'generated_text': 'The earth is flat, and there is no life'},\n",
       " {'generated_text': 'The earth is flat, and there is nothing in'},\n",
       " {'generated_text': 'The earth is full of life, and the sun'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"The earth is\", max_length = 10, num_return_sequences = 10, temperature = 0.8, num_beams = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few-Shot Leanrning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n",
      "Text: I hate it when my phone battery dies.\n",
      "Sentiment: Negative\n",
      "###\n",
      "Text: My dad has been really great!\n",
      "Sentiment: Positive\n",
      "###\n",
      "Text: This new music video is so good.\n",
      "Sentiment: Positive\n",
      "###\n",
      "Text: I love this video.\n",
      "Sentiment: Positive\n",
      "###\n",
      "Text: I love this video.\n",
      "Sentiment: Positive\n",
      "###\n",
      "Text: I love this video.\n",
      "Sentiment: Positive\n",
      "###\n",
      "Text\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"\"\"Sentiment Analysis\n",
    "Text: I hate it when my phone battery dies.\n",
    "Sentiment: Negative\n",
    "###\n",
    "Text: My dad has been really great!\n",
    "Sentiment: Positive\n",
    "###\n",
    "Text: This new music video is so good.\n",
    "Sentiment:\"\"\", top_k = 2, temperature = 0.1, max_new_tokens = 50)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for this task, GPT2 is not pretrained to do Sentiment Analysis, but based on a few examples, it is able to do it\n",
    "\n",
    "This is due to few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question/Answering\n",
      "C: Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock.\n",
      "Q: When was Google founded?\n",
      "A: 1998\n",
      "###\n",
      "C: Hugging Face is a company which develops social AI-run chatbot applications. It was established in 2016 by Clement Delangue and Julien Chaumond. The company is based in Brooklyn, New York, United States.\n",
      "Q: What does Hugging Face develop?\n",
      "A: social AI-run chatbot applications\n",
      "###\n",
      "C: The New York Jets are a professional American football team based in the New York metropolitan area. The Jets compete in the National Football League (NFL) as a member club of the league's American Football Conference (AFC) East division.\n",
      "Q: What division do the Jets play in?\n",
      "A: American Football Conference (AFC) East\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"\"\"Question/Answering\n",
    "C: Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University in California. Together they own about 14 percent of its shares and control 56 percent of the stockholder voting power through supervoting stock.\n",
    "Q: When was Google founded?\n",
    "A: 1998\n",
    "###\n",
    "C: Hugging Face is a company which develops social AI-run chatbot applications. It was established in 2016 by Clement Delangue and Julien Chaumond. The company is based in Brooklyn, New York, United States.\n",
    "Q: What does Hugging Face develop?\n",
    "A: social AI-run chatbot applications\n",
    "###\n",
    "C: The New York Jets are a professional American football team based in the New York metropolitan area. The Jets compete in the National Football League (NFL) as a member club of the league's American Football Conference (AFC) East division.\n",
    "Q: What division do the Jets play in?\n",
    "A:\"\"\", top_k=2, num_beams=2, max_length=215, temperature=0.5)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question/Answering\n",
      "C: The New York Jets are a professional American football team based in the New York metropolitan area. The Jets compete in the National Football League (NFL) as a member club of the league's American Football Conference (AFC) East division.\n",
      "Q: What division do the Jets play in?\n",
      "A: The New York Jets play in the AFC East. The\n"
     ]
    }
   ],
   "source": [
    "# sample for zero-shot learning\n",
    "\n",
    "print(generator(\n",
    "    '''Question/Answering\n",
    "C: The New York Jets are a professional American football team based in the New York metropolitan area. The Jets compete in the National Football League (NFL) as a member club of the league's American Football Conference (AFC) East division.\n",
    "Q: What division do the Jets play in?\n",
    "A:''',\n",
    "    top_k=2, num_beams=2, max_length=80, temperature=0.5)[0]['generated_text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis\n",
      "Text: This new music video was so good\n",
      "Sentiment: I'm so glad you liked it\n",
      "Sentiment: I'm so glad you liked it\n",
      "Sentiment: I'm so glad you liked it\n",
      "Sentiment: I'm so glad you\n"
     ]
    }
   ],
   "source": [
    "print(generator(\"\"\"Sentiment Analysis\n",
    "Text: This new music video was so good\n",
    "Sentiment:\"\"\", top_k=2, temperature=0.1, max_length=55)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero shot learning is not suitable for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_summarize = \"\"\"This training will focus on how the GPT family of models are used for NLP tasks including abstractive text summarization and natural language generation. The training will begin with an introduction to necessary concepts including masked self attention, language models, and transformers and then build on those concepts to introduce the GPT architecture. We will then move into how GPT is used for multiple natural language processing tasks with hands-on examples of using pre-trained GPT-2 models as well as fine-tuning these models on custom corpora.\n",
    "GPT models are some of the most relevant NLP architectures today and it is closely related to other important NLP deep learning models like BERT. Both of these models are derived from the newly invented transformer architecture and represent an inflection point in how machines process language and context.\n",
    "The Natural Language Processing with Next-Generation Transformer Architectures series of online trainings provides a comprehensive overview of state-of-the-art natural language processing (NLP) models including GPT and BERT which are derived from the modern attention-driven transformer architecture and the applications these models are used to solve today. All of the trainings in the series blend theory and application through the combination of visual mathematical explanations, straightforward applicable Python examples within hands-on Jupyter notebook demos, and comprehensive case studies featuring modern problems solvable by NLP models. (Note that at any given time, only a subset of these classes will be scheduled and open for registration.)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization Task:\n",
      "This training will focus on how the GPT family of models are used for NLP tasks including abstractive text summarization and natural language generation. The training will begin with an introduction to necessary concepts including masked self attention, language models, and transformers and then build on those concepts to introduce the GPT architecture. We will then move into how GPT is used for multiple natural language processing tasks with hands-on examples of using pre-trained GPT-2 models as well as fine-tuning these models on custom corpora.\n",
      "GPT models are some of the most relevant NLP architectures today and it is closely related to other important NLP deep learning models like BERT. Both of these models are derived from the newly invented transformer architecture and represent an inflection point in how machines process language and context.\n",
      "The Natural Language Processing with Next-Generation Transformer Architectures series of online trainings provides a comprehensive overview of state-of-the-art natural language processing (NLP) models including GPT and BERT which are derived from the modern attention-driven transformer architecture and the applications these models are used to solve today. All of the trainings in the series blend theory and application through the combination of visual mathematical explanations, straightforward applicable Python examples within hands-on Jupyter notebook demos, and comprehensive case studies featuring modern problems solvable by NLP models. (Note that at any given time, only a subset of these classes will be scheduled and open for registration.)\n",
      "TL;DR: This course is designed to teach you how to build and use the latest and greatest natural-language processing architectures. It will also provide you with the tools you need to develop and test your own natural languages. If you have any questions or comments, please feel free to email me at [email protected] or send me an e-mail. I look forward to hearing from you all!\n",
      "If you are interested in learning more about the nature of machine learning and how it can be applied to real-world problems, you can check out the following resources: http://www.neuroscience.com/learn-machine-learning-and-how-it-can-be-used-to-make-your-brain-feel-better/\n"
     ]
    }
   ],
   "source": [
    "print(generator(\n",
    "    f\"\"\"Summarization Task:\\n{to_summarize}\\nTL;DR:\"\"\", \n",
    "    max_length=512, top_k=5, num_beams=5, temperature=0.5, no_repeat_ngram_size=2 \n",
    ")[0]['generated_text']) \n",
    "\n",
    "# no_repeat_ngram_size = x     parameter suggest that model not uses same tokens in a sequence of x tokens.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TLDR (Too Long Didn't Read) is the reddit summarization algo.\n",
    "\n",
    "And beacuse GPT-2 is pre-trained on reddit data, it picks that up and hence GPT-2 is able to perform the task as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero Shot learning is good for abstract summarization task"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
