{"cells":[{"cell_type":"markdown","metadata":{"id":"4miMXqZ3t7v2"},"source":["# GPT for code dictation"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":550,"status":"ok","timestamp":1744576167271,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"2dgd7hZ1tGmO"},"outputs":[],"source":["from transformers import GPT2Tokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer, GPT2LMHeadModel, pipeline, TextDataset\n","from datasets import Dataset\n","import pandas as pd"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1744575666986,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"l_fv_6ZNt_bT","outputId":"02c125cd-119d-4793-ad92-965bd5132209"},"outputs":[{"name":"stdout","output_type":"stream","text":["(50, 2)\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"data\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"English\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"g of x equals integral from 0 to 10 of x cubed\",\n          \"sum from 0 to 5 of x\",\n          \"sum from 1 to x of x squared\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LaTeX\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"g(x) = \\\\int_{0}^{10} x^3 \\\\,dx\",\n          \"\\\\sum_{0}^{5} x\",\n          \"\\\\sum_{1}^{x} x^2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"data"},"text/html":["\n","  <div id=\"df-a9e2f7dc-caa2-4c2f-b8a8-cdf429558fdf\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>English</th>\n","      <th>LaTeX</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>integral from a to b of x squared</td>\n","      <td>\\int_{a}^{b} x^2 \\,dx</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>integral from negative 1 to 1 of x squared</td>\n","      <td>\\int_{-1}^{1} x^2 \\,dx</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9e2f7dc-caa2-4c2f-b8a8-cdf429558fdf')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a9e2f7dc-caa2-4c2f-b8a8-cdf429558fdf button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a9e2f7dc-caa2-4c2f-b8a8-cdf429558fdf');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-21ddf44d-9b79-41b4-b93c-17a3e4956246\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-21ddf44d-9b79-41b4-b93c-17a3e4956246')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-21ddf44d-9b79-41b4-b93c-17a3e4956246 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                      English                   LaTeX\n","0           integral from a to b of x squared   \\int_{a}^{b} x^2 \\,dx\n","1  integral from negative 1 to 1 of x squared  \\int_{-1}^{1} x^2 \\,dx"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('../data/english_to_latex.csv')\n","\n","print(data.shape)\n","\n","data.head(2)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304,"referenced_widgets":["fcce57476038407c921c926a890cb9b4","acfb3818363649e0abdb6015a759e4aa","d25f79fea21f40ff88d41a7fca1f9478","49a7757c7ac7491fb920572df10368a1","6063858aa4b64d0b982a8d48d9e09a73","48ef55308b4547f2bfae65a4304896b4","7f2e22af886c410ba97aa42ab876f89b","b09f3ab5591945dab7aaa855897d4440","7ab5f74c09234fef81773739883e51f9","37aacb27d0fa43ffbf89f910688f25c6","b035e325aa8e42fca7b502b7f01239dd","46c2148e7ecf4b4f9c48b44d2d91bf08","6d21a06c92864117937140565bf24156","68e2c479d21149a2b0bf159fd9fd6809","7140b30636a34242ad2e8129a01846e4","1a1c55ef9d7349ae92757ef909749a36","b2112f782b1a4b23a920bd3ca6a89d63","334be5fc80264225b35bc87cdaf264dc","7c46af106b1f4bd194acb8b381888ae8","baf28f2296264098811a851b07b0e713","742cc32fde12421ca3a49abc8341808a","0795412a20944208b76dff2d63ebe0bf","48e07569a0cf430e90d8bb4b8722dc01","01992621afc94ead932a33678e9804be","99b00bf42c0c4746a17f214029f32dc6","d43b1e59c8724a5dbc8393ff9818648b","4e96a73b4fd64d659c8ae750e221147f","7b62508c5f774c34a3490d5a7347f701","12d99cb359934b9eb73a02b6baaa73a5","c842f3e696bf41f5ab9d922d96b6a1dc","9029b7f540d546c2bcbc173d2a2d635b","7ac89da1f59343b3b2a5dd113d047b93","ae907cab4fd04c4e9dddfba9dfeff400","6d5e3c3ae1c249daa02dc7492ea5a681","d5591b9a46694f1ca9a74383d96ceaee","798b1776d8d0405fb9ddc751c6f77e1a","5dda00c87e1f4841abaebcbb5c3029ca","c1d8b3f9836f4523a01a682e6910fd27","8b36c115deb44f40b2c0a77fcf28ccb5","74b983edaf554a3aaa671770366ff613","c25da016a258424ebe1473ba3484cff2","2962f566ae744a9aae3e32f66e22cd7a","b435f1a697c044558a2091fea57234cf","287497d518534a4cb8f46489350734ca","2f6ade66d3c34f5e9690aec53a2f4bd6","4cb9ce5d117c4d0e923fe3464f38b19a","c5dd179b6cc6476ca1ed13d6f1c78a3e","c4ce6bd07588441aa72be329059f4e64","d9b55257a93240ef8e62d8bb37b130f7","e45542eda5354999abbcd842fca1c226","09a15be01bad4ed6968df6afe31159be","647139a37bc74b31afc66c2a8cba9f48","f1e5d2532f514f17a858802739923b27","eacc9045df96488d82b4b103bccb9e2c","1d4e1a631ca5496683bec353b0710118"]},"executionInfo":{"elapsed":2527,"status":"ok","timestamp":1744575670030,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"sLC8t0EPufxy","outputId":"6213292a-ab25-4eef-9e2d-ed0f3b25ed58"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcce57476038407c921c926a890cb9b4","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"46c2148e7ecf4b4f9c48b44d2d91bf08","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48e07569a0cf430e90d8bb4b8722dc01","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d5e3c3ae1c249daa02dc7492ea5a681","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f6ade66d3c34f5e9690aec53a2f4bd6","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Add our singular prompt\n","CONVERSION_PROMPT = 'LCT\\n'  # LaTeX conversion task\n","\n","CONVERSION_TOKEN = 'LaTeX:'"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1744575670131,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"u_vC9ueZujAa","outputId":"4d86834d-1f8c-427f-ca99-4ac5148afbbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["LCT\n","English: integral from a to b of x squared\n","LaTeX: \\int_{a}^{b} x^2 \\,dx\n"]}],"source":["training_examples = f'{CONVERSION_PROMPT}English: ' + data['English'] + '\\n' + CONVERSION_TOKEN + ' ' + data['LaTeX'].astype(str)\n","\n","print(training_examples[0])"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1744575670134,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"uXIfmx2wunKW","outputId":"2f83fc18-9885-41a7-92ea-d718c971e892"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"task_df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 49,\n        \"samples\": [\n          \"LCT\\nEnglish: g of x equals integral from 0 to 10 of x cubed\\nLaTeX: g(x) = \\\\int_{0}^{10} x^3 \\\\,dx\",\n          \"LCT\\nEnglish: sum from 0 to 5 of x\\nLaTeX: \\\\sum_{0}^{5} x\",\n          \"LCT\\nEnglish: sum from 1 to x of x squared\\nLaTeX: \\\\sum_{1}^{x} x^2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"task_df"},"text/html":["\n","  <div id=\"df-7d1943f6-7a22-4a63-bcb0-4778a0aaab58\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>LCT\\nEnglish: integral from a to b of x square...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>LCT\\nEnglish: integral from negative 1 to 1 of...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d1943f6-7a22-4a63-bcb0-4778a0aaab58')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-7d1943f6-7a22-4a63-bcb0-4778a0aaab58 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-7d1943f6-7a22-4a63-bcb0-4778a0aaab58');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fa3e41c9-57c5-4d1b-90aa-fb461ce74074\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa3e41c9-57c5-4d1b-90aa-fb461ce74074')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fa3e41c9-57c5-4d1b-90aa-fb461ce74074 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                                text\n","0  LCT\\nEnglish: integral from a to b of x square...\n","1  LCT\\nEnglish: integral from negative 1 to 1 of..."]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["task_df = pd.DataFrame({'text': training_examples})\n","\n","task_df.head(2)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["89fe31165ba04a6d876ee7fa88b9762d","80f61097bcbc433f864e0e0011f45456","afe5ede5374e4380a7aae3da3f07d644","a87fce260365470080c15ce4c9cbdd80","fd63d746ff454d97abd8a6a6ffd18dd5","c273ed378f3b49a197d881f76d81b240","687585daca5940e791b0a56cf4c0a1b6","52f7b568504348669ad6acc018c3ecb3","b561e299bd81416c8f50995f0b30c8de","671d4bca861047239be9495a291fd6a3","ea7b4bf8c8e646f0b815b499593b9e35"]},"executionInfo":{"elapsed":1974,"status":"ok","timestamp":1744575672109,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"Ng-ACICjuo2w","outputId":"3d0750bc-a78d-4b0c-ffa1-ae8c370b3d1b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"89fe31165ba04a6d876ee7fa88b9762d","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/50 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["latex_data = Dataset.from_pandas(task_df)  # turn a pandas DataFrame into a Dataset\n","\n","def preprocess(examples):  # tokenize our text but don't pad because our collator will pad for us dynamically\n","    return tokenizer(examples['text'], truncation=True)\n","\n","latex_data = latex_data.map(preprocess, batched=True)\n","\n","latex_data = latex_data.train_test_split(train_size=.8)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1744575672119,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"oJPgPQ58uqXV"},"outputs":[],"source":["data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"referenced_widgets":["0d17c357bb2041d4aa92af3f77259273","4d5b5cfc3dc34212815b238f39b059d0","23e117e17ac549c991598bca04a362ac","51b04a875e3a40ea815eeb67e7afcd3c","e8d0740fdeff4fddb98f6594368c7889","4de5ecceceb94e638a9cecfcdc65350a","23294e6b1b2d45dc8bed1039d8c7f6e3","bbb258d6aedd4e00bae853e642a9eae8","501a4be6080c44f7a7b50b342a17cb73","692250f402aa4cd589de689d8a20190b","22cabeeb8e3940eb8a9516d4a0b562e1","59abfe3db6464deca0d511061de7dbc3","6c4a96b00cb44ee4a37978f2a929c52c","7740bb3f85bc45d481fe22dbd89dfb5e","521a1c272313444891fdf79d457239ad","28058b6ecffc4607aad742b81cf0e932","5ab10780afad4ad5a2b5366cab92e3aa","650b8d116049406da3b37fc1b4744b28","0132bd7e7ebe4102a4c8a20247f0adfa","677d5f1c063046818a871d42955cd76c","ef97cddfff9040aaa7280f31a56e51d7","83057695ea6b41749491b5997a9ac1ba"]},"executionInfo":{"elapsed":5426,"status":"ok","timestamp":1744575677546,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"tWd7LrShutqf","outputId":"03c94814-45d4-45e2-d3ba-ee64ea02e023"},"outputs":[{"name":"stderr","output_type":"stream","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d17c357bb2041d4aa92af3f77259273","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59abfe3db6464deca0d511061de7dbc3","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["latex_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"executionInfo":{"elapsed":36101,"status":"ok","timestamp":1744575713648,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"FM1Pq3zXuu20","outputId":"250aa158-5043-49e4-95e4-6cbd19daf1db"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter:"]},{"name":"stdout","output_type":"stream","text":[" 路路路路路路路路路路\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnt_\u001b[0m (\u001b[33meshaan-rithesh2023-vit-chennai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.19.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20250413_202152-iwhqdo48</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface/runs/iwhqdo48' target=\"_blank\">./english_to_latex</a></strong> to <a href='https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface' target=\"_blank\">https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface/runs/iwhqdo48' target=\"_blank\">https://wandb.ai/eshaan-rithesh2023-vit-chennai/huggingface/runs/iwhqdo48</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 5.111514568328857,\n"," 'eval_model_preparation_time': 0.0055,\n"," 'eval_runtime': 0.7526,\n"," 'eval_samples_per_second': 13.287,\n"," 'eval_steps_per_second': 1.329}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["training_args = TrainingArguments(\n","    output_dir=\"./english_to_latex\",\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=10, # number of training epochs\n","    per_device_train_batch_size=2, # batch size for training\n","    per_device_eval_batch_size=20,  # batch size for evaluation\n","    load_best_model_at_end=True,\n","    logging_steps=5,\n","    log_level='info',\n","    evaluation_strategy='epoch',\n","    save_strategy='epoch'\n",")\n","\n","trainer = Trainer(\n","    model=latex_gpt2,\n","    args=training_args,\n","    train_dataset=latex_data[\"train\"],\n","    eval_dataset=latex_data[\"test\"],\n","    data_collator=data_collator,\n",")\n","\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":113924,"status":"ok","timestamp":1744575827573,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"CLXQbFwquxeQ","outputId":"275d85d5-ecce-494d-eccf-acc852d48349"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 40\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 200\n","  Number of trainable parameters = 124,439,808\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 01:53, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Model Preparation Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.522400</td>\n","      <td>1.009291</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.753000</td>\n","      <td>0.715061</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.749800</td>\n","      <td>0.599575</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.626700</td>\n","      <td>0.546577</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.653400</td>\n","      <td>0.544049</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.455200</td>\n","      <td>0.507555</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.402700</td>\n","      <td>0.532265</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.401900</td>\n","      <td>0.559123</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.369500</td>\n","      <td>0.526749</td>\n","      <td>0.005500</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.313300</td>\n","      <td>0.523715</td>\n","      <td>0.005500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:32]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./english_to_latex/checkpoint-20\n","Configuration saved in ./english_to_latex/checkpoint-20/config.json\n","Configuration saved in ./english_to_latex/checkpoint-20/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-20/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-20/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-20/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-40\n","Configuration saved in ./english_to_latex/checkpoint-40/config.json\n","Configuration saved in ./english_to_latex/checkpoint-40/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-40/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-40/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-40/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-60\n","Configuration saved in ./english_to_latex/checkpoint-60/config.json\n","Configuration saved in ./english_to_latex/checkpoint-60/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-60/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-60/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-60/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-80\n","Configuration saved in ./english_to_latex/checkpoint-80/config.json\n","Configuration saved in ./english_to_latex/checkpoint-80/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-80/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-80/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-80/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-100\n","Configuration saved in ./english_to_latex/checkpoint-100/config.json\n","Configuration saved in ./english_to_latex/checkpoint-100/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-100/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-100/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-120\n","Configuration saved in ./english_to_latex/checkpoint-120/config.json\n","Configuration saved in ./english_to_latex/checkpoint-120/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-120/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-120/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-120/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-140\n","Configuration saved in ./english_to_latex/checkpoint-140/config.json\n","Configuration saved in ./english_to_latex/checkpoint-140/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-140/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-140/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-140/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-160\n","Configuration saved in ./english_to_latex/checkpoint-160/config.json\n","Configuration saved in ./english_to_latex/checkpoint-160/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-160/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-160/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-160/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-180\n","Configuration saved in ./english_to_latex/checkpoint-180/config.json\n","Configuration saved in ./english_to_latex/checkpoint-180/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-180/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-180/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-180/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./english_to_latex/checkpoint-200\n","Configuration saved in ./english_to_latex/checkpoint-200/config.json\n","Configuration saved in ./english_to_latex/checkpoint-200/generation_config.json\n","Model weights saved in ./english_to_latex/checkpoint-200/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./english_to_latex/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in ./english_to_latex/checkpoint-200/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./english_to_latex/checkpoint-120 (score: 0.5075546503067017).\n","There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"]},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=0.7454731261730194, metrics={'train_runtime': 113.5611, 'train_samples_per_second': 3.522, 'train_steps_per_second': 1.761, 'total_flos': 6238347264000.0, 'train_loss': 0.7454731261730194, 'epoch': 10.0})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"executionInfo":{"elapsed":82,"status":"ok","timestamp":1744575827662,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"v7evGUaOu69U","outputId":"2b6fbfbf-c9ef-485f-a729-f288c65b6aea"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.5075546503067017,\n"," 'eval_model_preparation_time': 0.0055,\n"," 'eval_runtime': 0.0595,\n"," 'eval_samples_per_second': 168.021,\n"," 'eval_steps_per_second': 16.802,\n"," 'epoch': 10.0}"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2325,"status":"ok","timestamp":1744576172394,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"eD1m_FWX0DlU","outputId":"7fbe427d-01fc-4a0a-b0e8-c5f54fbcea8e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the  Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n","Creating features from dataset file at .\n","Saving features into cached file ./cached_lm_GPT2Tokenizer_32_calculus made easy.txt [took 0.012 s]\n"]}],"source":["calculus_data = TextDataset(\n","    tokenizer = tokenizer,\n","    file_path = \"../data/calculus made easy.txt\",\n","    block_size = 32\n",")\n","\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer = tokenizer, mlm = False\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2631,"status":"ok","timestamp":1744576232409,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"hFyjbLl90sLy","outputId":"e7cf82d2-df3f-4cd9-81e2-600559b393b5"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.50.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n"]}],"source":["latex_gpt2 = GPT2LMHeadModel.from_pretrained('gpt2')"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1744576335742,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"wqmBoymT2F9f","outputId":"dac0e527-e5fa-4f01-d62d-1ccf7e9661fa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"]},{"data":{"text/plain":["{'eval_loss': 5.111514568328857,\n"," 'eval_model_preparation_time': 0.0032,\n"," 'eval_runtime': 0.0592,\n"," 'eval_samples_per_second': 168.878,\n"," 'eval_steps_per_second': 16.888}"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["training_args = TrainingArguments(\n","    output_dir=\"./calculus_english_to_latex\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=10,\n","    per_device_train_batch_size=2,\n","    per_device_eval_batch_size=20,\n","    load_best_model_at_end=True,\n","    logging_steps=5,\n","    log_level='info',\n","    evaluation_strategy='epoch',\n","    save_strategy='epoch'\n",")\n","\n","trainer = Trainer(\n","    model=latex_gpt2,\n","    args=training_args,\n","    train_dataset=latex_data[\"train\"],\n","    eval_dataset=latex_data[\"test\"],\n","    data_collator=data_collator,\n",")\n","\n","trainer.evaluate()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":123818,"status":"ok","timestamp":1744576476866,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"yGmZDmLM2igq","outputId":"9b2cb528-0d2a-44ac-e5b9-43b46d771e58"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 40\n","  Num Epochs = 10\n","  Instantaneous batch size per device = 2\n","  Total train batch size (w. parallel, distributed & accumulation) = 2\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 200\n","  Number of trainable parameters = 124,439,808\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/200 02:03, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Model Preparation Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.522400</td>\n","      <td>1.009291</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.753000</td>\n","      <td>0.715061</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.749800</td>\n","      <td>0.599575</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.626700</td>\n","      <td>0.546577</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.653400</td>\n","      <td>0.544049</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.455200</td>\n","      <td>0.507555</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.402700</td>\n","      <td>0.532265</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.401900</td>\n","      <td>0.559123</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.369500</td>\n","      <td>0.526749</td>\n","      <td>0.003200</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.313300</td>\n","      <td>0.523715</td>\n","      <td>0.003200</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 00:19]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./calculus_english_to_latex/checkpoint-20\n","Configuration saved in ./calculus_english_to_latex/checkpoint-20/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-20/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-20/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-20/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-20/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-40\n","Configuration saved in ./calculus_english_to_latex/checkpoint-40/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-40/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-40/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-40/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-40/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-60\n","Configuration saved in ./calculus_english_to_latex/checkpoint-60/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-60/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-60/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-60/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-60/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-80\n","Configuration saved in ./calculus_english_to_latex/checkpoint-80/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-80/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-80/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-80/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-80/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-100\n","Configuration saved in ./calculus_english_to_latex/checkpoint-100/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-100/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-100/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-100/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-100/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-120\n","Configuration saved in ./calculus_english_to_latex/checkpoint-120/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-120/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-120/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-120/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-120/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-140\n","Configuration saved in ./calculus_english_to_latex/checkpoint-140/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-140/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-140/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-140/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-140/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-160\n","Configuration saved in ./calculus_english_to_latex/checkpoint-160/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-160/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-160/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-160/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-160/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-180\n","Configuration saved in ./calculus_english_to_latex/checkpoint-180/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-180/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-180/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-180/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-180/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n","Saving model checkpoint to ./calculus_english_to_latex/checkpoint-200\n","Configuration saved in ./calculus_english_to_latex/checkpoint-200/config.json\n","Configuration saved in ./calculus_english_to_latex/checkpoint-200/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/checkpoint-200/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/checkpoint-200/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/checkpoint-200/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ./calculus_english_to_latex/checkpoint-120 (score: 0.5075546503067017).\n","There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"]},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=0.7454731261730194, metrics={'train_runtime': 123.2432, 'train_samples_per_second': 3.246, 'train_steps_per_second': 1.623, 'total_flos': 6238347264000.0, 'train_loss': 0.7454731261730194, 'epoch': 10.0})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"executionInfo":{"elapsed":66,"status":"ok","timestamp":1744576477168,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"o5WrWuxi2oN7","outputId":"7208091a-6870-4171-dc10-d0409d684e8c"},"outputs":[{"name":"stderr","output_type":"stream","text":["The following columns in the evaluation set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: text. If text are not expected by `GPT2LMHeadModel.forward`,  you can safely ignore this message.\n","\n","***** Running Evaluation *****\n","  Num examples = 10\n","  Batch size = 20\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1/1 : < :]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'eval_loss': 0.5075546503067017,\n"," 'eval_model_preparation_time': 0.0032,\n"," 'eval_runtime': 0.0499,\n"," 'eval_samples_per_second': 200.217,\n"," 'eval_steps_per_second': 20.022,\n"," 'epoch': 10.0}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1926,"status":"ok","timestamp":1744576479096,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"1Q8Wsr-02sz6","outputId":"5ee73f52-85ae-4cc5-fcca-436741dd0a01"},"outputs":[{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to ./calculus_english_to_latex\n","Configuration saved in ./calculus_english_to_latex/config.json\n","Configuration saved in ./calculus_english_to_latex/generation_config.json\n","Model weights saved in ./calculus_english_to_latex/model.safetensors\n","Saving Trainer.data_collator.tokenizer by default as Trainer.processing_class is `None`\n","tokenizer config file saved in ./calculus_english_to_latex/tokenizer_config.json\n","Special tokens file saved in ./calculus_english_to_latex/special_tokens_map.json\n"]}],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":212,"status":"ok","timestamp":1744576479312,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"qFQ74Bb9210m","outputId":"b099de3b-05c0-44d4-ffb7-c6779d06b130"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file ./calculus_english_to_latex/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.50.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file ./calculus_english_to_latex/model.safetensors\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at ./calculus_english_to_latex.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","loading configuration file ./calculus_english_to_latex/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","Device set to use cuda:0\n"]}],"source":["loaded_model = GPT2LMHeadModel.from_pretrained('./calculus_english_to_latex')\n","latex_generator = pipeline('text-generation', model=loaded_model, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1744576479364,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"LkbkGkQ-241B","outputId":"9ff66fdc-69b2-4cd8-c7b5-99f003d2acea"},"outputs":[{"name":"stdout","output_type":"stream","text":["LCT\n","English: f of x equals integral from 0 to pi of x to the fourth power\n","LaTeX:\n"]}],"source":["text_sample = 'f of x equals integral from 0 to pi of x to the fourth power'\n","conversion_text_sample = f'{CONVERSION_PROMPT}English: {text_sample}\\n{CONVERSION_TOKEN}'\n","\n","print(conversion_text_sample)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":780,"status":"ok","timestamp":1744576480146,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"6EQ7QIXG26mL","outputId":"8db1bbd7-9707-451b-f598-c82f58ad5942"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["LCT\n","English: f of x equals integral from 0 to pi of x to the fourth power\n","LaTeX: f(x) = \\int_{0}^{5} x^4 \\,dx^\n"]}],"source":["print(latex_generator(\n","    conversion_text_sample, num_beams=5, early_stopping=True, temperature=0.7,\n","    max_length=len(tokenizer.encode(conversion_text_sample)) + 20\n",")[0]['generated_text'])"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":246,"status":"ok","timestamp":1744576480391,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"STLijWMK273q","outputId":"c22b6e60-1ee9-49fe-c94f-08e2d3852550"},"outputs":[{"name":"stdout","output_type":"stream","text":["LCT\n","English: f of x is sum from 0 to x of x squared\n","LaTeX: f(x) = \\sum_{0}^{x} x^2 \\,dx^\n"]}],"source":["text_sample = 'f of x is sum from 0 to x of x squared'\n","conversion_text_sample = f'{CONVERSION_PROMPT}English: {text_sample}\\n{CONVERSION_TOKEN}'\n","\n","print(latex_generator(\n","    conversion_text_sample, num_beams=5, early_stopping=True, temperature=0.7,\n","    max_length=len(tokenizer.encode(conversion_text_sample)) + 20\n",")[0]['generated_text'])"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2716,"status":"ok","timestamp":1744576585128,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"GHhit-_8291f","outputId":"d071f173-aa19-44f7-97e9-80887ec32a20"},"outputs":[{"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.50.3\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n","Generate config GenerationConfig {\n","  \"bos_token_id\": 50256,\n","  \"eos_token_id\": 50256\n","}\n","\n","Device set to use cuda:0\n"]}],"source":["non_finetuned_latex_generator = pipeline(\n","    'text-generation',\n","    model=GPT2LMHeadModel.from_pretrained('gpt2'),\n","    tokenizer=tokenizer\n",")"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1744576585137,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"Nxfj8c5l3FHu"},"outputs":[],"source":["few_shot_prompt = \"\"\"LCT\n","English: f of x is sum from 0 to x of x squared\n","LaTeX: f(x) = \\sum_{0}^{x} x^2 \\,dx \\\n","###\n","LCT\n","English: f of x equals integral from 0 to pi of x to the fourth power\n","LaTeX: f(x) = \\int_{0}^{\\pi} x^4 \\,dx \\\n","###\n","LCT\n","English: x squared\n","LaTeX:\"\"\""]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1744576587805,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"NBjdCCXL3F47","outputId":"d0ad310d-6cf5-4846-bd77-2bc370ccecdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["LCT\n","English: f of x is sum from 0 to x of x squared\n","LaTeX: f(x) = \\sum_{0}^{x} x^2 \\,dx ###\n","LCT\n","English: f of x equals integral from 0 to pi of x to the fourth power\n","LaTeX: f(x) = \\int_{0}^{\\pi} x^4 \\,dx ###\n","LCT\n","English: x squared\n","LaTeX: f(x) = \\sum_{0}^{x} x^2 \\,dx ###\n"]}],"source":["print(non_finetuned_latex_generator(\n","    few_shot_prompt, num_beams=5, early_stopping=True, temperature=0.7,\n","    max_length=len(tokenizer.encode(few_shot_prompt)) + 20\n",")[0]['generated_text'])"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1744576589766,"user":{"displayName":"Niket Girdhar 22BLC1044","userId":"04906161325698823566"},"user_tz":-330},"id":"KoI961xo3HV6","outputId":"18a32358-7c7d-4418-912e-d42a5a901663"},"outputs":[{"name":"stdout","output_type":"stream","text":["LCT\n","English: f of x is sum from 0 to x of x squared\n","LaTeX: f of x is sum from 0 to x of x squared\n","LaTeX: f of x is\n"]}],"source":["print(non_finetuned_latex_generator(\n","    conversion_text_sample, num_beams=5, early_stopping=True, temperature=0.7,\n","    max_length=len(tokenizer.encode(conversion_text_sample)) + 20\n",")[0]['generated_text'])"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOsnBwqbF+Sz4KsOVTr5zi8","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0132bd7e7ebe4102a4c8a20247f0adfa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01992621afc94ead932a33678e9804be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b62508c5f774c34a3490d5a7347f701","placeholder":"","style":"IPY_MODEL_12d99cb359934b9eb73a02b6baaa73a5","value":"merges.txt:100%"}},"0795412a20944208b76dff2d63ebe0bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09a15be01bad4ed6968df6afe31159be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0d17c357bb2041d4aa92af3f77259273":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d5b5cfc3dc34212815b238f39b059d0","IPY_MODEL_23e117e17ac549c991598bca04a362ac","IPY_MODEL_51b04a875e3a40ea815eeb67e7afcd3c"],"layout":"IPY_MODEL_e8d0740fdeff4fddb98f6594368c7889"}},"12d99cb359934b9eb73a02b6baaa73a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1a1c55ef9d7349ae92757ef909749a36":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d4e1a631ca5496683bec353b0710118":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22cabeeb8e3940eb8a9516d4a0b562e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23294e6b1b2d45dc8bed1039d8c7f6e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23e117e17ac549c991598bca04a362ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbb258d6aedd4e00bae853e642a9eae8","max":548105171,"min":0,"orientation":"horizontal","style":"IPY_MODEL_501a4be6080c44f7a7b50b342a17cb73","value":548105171}},"28058b6ecffc4607aad742b81cf0e932":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"287497d518534a4cb8f46489350734ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2962f566ae744a9aae3e32f66e22cd7a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f6ade66d3c34f5e9690aec53a2f4bd6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cb9ce5d117c4d0e923fe3464f38b19a","IPY_MODEL_c5dd179b6cc6476ca1ed13d6f1c78a3e","IPY_MODEL_c4ce6bd07588441aa72be329059f4e64"],"layout":"IPY_MODEL_d9b55257a93240ef8e62d8bb37b130f7"}},"334be5fc80264225b35bc87cdaf264dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37aacb27d0fa43ffbf89f910688f25c6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46c2148e7ecf4b4f9c48b44d2d91bf08":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6d21a06c92864117937140565bf24156","IPY_MODEL_68e2c479d21149a2b0bf159fd9fd6809","IPY_MODEL_7140b30636a34242ad2e8129a01846e4"],"layout":"IPY_MODEL_1a1c55ef9d7349ae92757ef909749a36"}},"48e07569a0cf430e90d8bb4b8722dc01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_01992621afc94ead932a33678e9804be","IPY_MODEL_99b00bf42c0c4746a17f214029f32dc6","IPY_MODEL_d43b1e59c8724a5dbc8393ff9818648b"],"layout":"IPY_MODEL_4e96a73b4fd64d659c8ae750e221147f"}},"48ef55308b4547f2bfae65a4304896b4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49a7757c7ac7491fb920572df10368a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37aacb27d0fa43ffbf89f910688f25c6","placeholder":"","style":"IPY_MODEL_b035e325aa8e42fca7b502b7f01239dd","value":"26.0/26.0[00:00&lt;00:00,972B/s]"}},"4cb9ce5d117c4d0e923fe3464f38b19a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e45542eda5354999abbcd842fca1c226","placeholder":"","style":"IPY_MODEL_09a15be01bad4ed6968df6afe31159be","value":"config.json:100%"}},"4d5b5cfc3dc34212815b238f39b059d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4de5ecceceb94e638a9cecfcdc65350a","placeholder":"","style":"IPY_MODEL_23294e6b1b2d45dc8bed1039d8c7f6e3","value":"model.safetensors:100%"}},"4de5ecceceb94e638a9cecfcdc65350a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e96a73b4fd64d659c8ae750e221147f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"501a4be6080c44f7a7b50b342a17cb73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"51b04a875e3a40ea815eeb67e7afcd3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_692250f402aa4cd589de689d8a20190b","placeholder":"","style":"IPY_MODEL_22cabeeb8e3940eb8a9516d4a0b562e1","value":"548M/548M[00:03&lt;00:00,163MB/s]"}},"521a1c272313444891fdf79d457239ad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef97cddfff9040aaa7280f31a56e51d7","placeholder":"","style":"IPY_MODEL_83057695ea6b41749491b5997a9ac1ba","value":"124/124[00:00&lt;00:00,3.78kB/s]"}},"52f7b568504348669ad6acc018c3ecb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59abfe3db6464deca0d511061de7dbc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6c4a96b00cb44ee4a37978f2a929c52c","IPY_MODEL_7740bb3f85bc45d481fe22dbd89dfb5e","IPY_MODEL_521a1c272313444891fdf79d457239ad"],"layout":"IPY_MODEL_28058b6ecffc4607aad742b81cf0e932"}},"5ab10780afad4ad5a2b5366cab92e3aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5dda00c87e1f4841abaebcbb5c3029ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b435f1a697c044558a2091fea57234cf","placeholder":"","style":"IPY_MODEL_287497d518534a4cb8f46489350734ca","value":"1.36M/1.36M[00:00&lt;00:00,14.5MB/s]"}},"6063858aa4b64d0b982a8d48d9e09a73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"647139a37bc74b31afc66c2a8cba9f48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"650b8d116049406da3b37fc1b4744b28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"671d4bca861047239be9495a291fd6a3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"677d5f1c063046818a871d42955cd76c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"687585daca5940e791b0a56cf4c0a1b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68e2c479d21149a2b0bf159fd9fd6809":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c46af106b1f4bd194acb8b381888ae8","max":1042301,"min":0,"orientation":"horizontal","style":"IPY_MODEL_baf28f2296264098811a851b07b0e713","value":1042301}},"692250f402aa4cd589de689d8a20190b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c4a96b00cb44ee4a37978f2a929c52c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ab10780afad4ad5a2b5366cab92e3aa","placeholder":"","style":"IPY_MODEL_650b8d116049406da3b37fc1b4744b28","value":"generation_config.json:100%"}},"6d21a06c92864117937140565bf24156":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2112f782b1a4b23a920bd3ca6a89d63","placeholder":"","style":"IPY_MODEL_334be5fc80264225b35bc87cdaf264dc","value":"vocab.json:100%"}},"6d5e3c3ae1c249daa02dc7492ea5a681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5591b9a46694f1ca9a74383d96ceaee","IPY_MODEL_798b1776d8d0405fb9ddc751c6f77e1a","IPY_MODEL_5dda00c87e1f4841abaebcbb5c3029ca"],"layout":"IPY_MODEL_c1d8b3f9836f4523a01a682e6910fd27"}},"7140b30636a34242ad2e8129a01846e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_742cc32fde12421ca3a49abc8341808a","placeholder":"","style":"IPY_MODEL_0795412a20944208b76dff2d63ebe0bf","value":"1.04M/1.04M[00:00&lt;00:00,7.19MB/s]"}},"742cc32fde12421ca3a49abc8341808a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b983edaf554a3aaa671770366ff613":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7740bb3f85bc45d481fe22dbd89dfb5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0132bd7e7ebe4102a4c8a20247f0adfa","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_677d5f1c063046818a871d42955cd76c","value":124}},"798b1776d8d0405fb9ddc751c6f77e1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c25da016a258424ebe1473ba3484cff2","max":1355256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2962f566ae744a9aae3e32f66e22cd7a","value":1355256}},"7ab5f74c09234fef81773739883e51f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ac89da1f59343b3b2a5dd113d047b93":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b62508c5f774c34a3490d5a7347f701":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c46af106b1f4bd194acb8b381888ae8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f2e22af886c410ba97aa42ab876f89b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80f61097bcbc433f864e0e0011f45456":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c273ed378f3b49a197d881f76d81b240","placeholder":"","style":"IPY_MODEL_687585daca5940e791b0a56cf4c0a1b6","value":"Map:100%"}},"83057695ea6b41749491b5997a9ac1ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89fe31165ba04a6d876ee7fa88b9762d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80f61097bcbc433f864e0e0011f45456","IPY_MODEL_afe5ede5374e4380a7aae3da3f07d644","IPY_MODEL_a87fce260365470080c15ce4c9cbdd80"],"layout":"IPY_MODEL_fd63d746ff454d97abd8a6a6ffd18dd5"}},"8b36c115deb44f40b2c0a77fcf28ccb5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9029b7f540d546c2bcbc173d2a2d635b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99b00bf42c0c4746a17f214029f32dc6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c842f3e696bf41f5ab9d922d96b6a1dc","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9029b7f540d546c2bcbc173d2a2d635b","value":456318}},"a87fce260365470080c15ce4c9cbdd80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_671d4bca861047239be9495a291fd6a3","placeholder":"","style":"IPY_MODEL_ea7b4bf8c8e646f0b815b499593b9e35","value":"50/50[00:00&lt;00:00,704.61examples/s]"}},"acfb3818363649e0abdb6015a759e4aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48ef55308b4547f2bfae65a4304896b4","placeholder":"","style":"IPY_MODEL_7f2e22af886c410ba97aa42ab876f89b","value":"tokenizer_config.json:100%"}},"ae907cab4fd04c4e9dddfba9dfeff400":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"afe5ede5374e4380a7aae3da3f07d644":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52f7b568504348669ad6acc018c3ecb3","max":50,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b561e299bd81416c8f50995f0b30c8de","value":50}},"b035e325aa8e42fca7b502b7f01239dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b09f3ab5591945dab7aaa855897d4440":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2112f782b1a4b23a920bd3ca6a89d63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b435f1a697c044558a2091fea57234cf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b561e299bd81416c8f50995f0b30c8de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"baf28f2296264098811a851b07b0e713":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bbb258d6aedd4e00bae853e642a9eae8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1d8b3f9836f4523a01a682e6910fd27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c25da016a258424ebe1473ba3484cff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c273ed378f3b49a197d881f76d81b240":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4ce6bd07588441aa72be329059f4e64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eacc9045df96488d82b4b103bccb9e2c","placeholder":"","style":"IPY_MODEL_1d4e1a631ca5496683bec353b0710118","value":"665/665[00:00&lt;00:00,16.9kB/s]"}},"c5dd179b6cc6476ca1ed13d6f1c78a3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_647139a37bc74b31afc66c2a8cba9f48","max":665,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f1e5d2532f514f17a858802739923b27","value":665}},"c842f3e696bf41f5ab9d922d96b6a1dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25f79fea21f40ff88d41a7fca1f9478":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b09f3ab5591945dab7aaa855897d4440","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7ab5f74c09234fef81773739883e51f9","value":26}},"d43b1e59c8724a5dbc8393ff9818648b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ac89da1f59343b3b2a5dd113d047b93","placeholder":"","style":"IPY_MODEL_ae907cab4fd04c4e9dddfba9dfeff400","value":"456k/456k[00:00&lt;00:00,6.22MB/s]"}},"d5591b9a46694f1ca9a74383d96ceaee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b36c115deb44f40b2c0a77fcf28ccb5","placeholder":"","style":"IPY_MODEL_74b983edaf554a3aaa671770366ff613","value":"tokenizer.json:100%"}},"d9b55257a93240ef8e62d8bb37b130f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e45542eda5354999abbcd842fca1c226":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8d0740fdeff4fddb98f6594368c7889":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea7b4bf8c8e646f0b815b499593b9e35":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eacc9045df96488d82b4b103bccb9e2c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef97cddfff9040aaa7280f31a56e51d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1e5d2532f514f17a858802739923b27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcce57476038407c921c926a890cb9b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_acfb3818363649e0abdb6015a759e4aa","IPY_MODEL_d25f79fea21f40ff88d41a7fca1f9478","IPY_MODEL_49a7757c7ac7491fb920572df10368a1"],"layout":"IPY_MODEL_6063858aa4b64d0b982a8d48d9e09a73"}},"fd63d746ff454d97abd8a6a6ffd18dd5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
