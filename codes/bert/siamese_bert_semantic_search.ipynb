{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese-BERT network for semantic searching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:11: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 2.3.0)\n",
      "  from scipy.sparse import csr_matrix, issparse\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "from random import sample, seed, shuffle\n",
    "from sentence_transformers import InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google SearchPlease click here if you are not redirected within a few seconds.If you're having trouble accessing Google Search, please click here, or send feedback.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 8.867191780836947e-08,\n",
       " 'start': 154,\n",
       " 'end': 164,\n",
       " 'answer': '\\xa0feedback.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERSON = 'Niket Girdhar'\n",
    "\n",
    "google_html = BeautifulSoup(requests.get(f'https://www.google.com/search?q={PERSON}').text).get_text()[:1024] # not a good way to search on google\n",
    "\n",
    "nlp = pipeline('question-answering', \n",
    "               model='deepset/roberta-base-squad2', \n",
    "               tokenizer='deepset/roberta-base-squad2', \n",
    "               max_length=10)\n",
    "\n",
    "print(google_html)\n",
    "nlp(f'Who is {PERSON}?', google_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might give some answer but that answer is based on some given context (html data extracted here)\n",
    "\n",
    "Task in hand is to find the context out of a massive corpora of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 70 documents/paragraphs\n"
     ]
    }
   ],
   "source": [
    "text = urlopen('https://www.gutenberg.org/cache/epub/10834/pg10834.txt').read().decode() # our dataset: textbook about insects\n",
    "\n",
    "documents = list(filter(lambda x: len(x) > 100, text.split('\\r\\n\\r\\n'))) # only keeps documents that have atleast 100 characters\n",
    "\n",
    "documents = np.array(documents)\n",
    "\n",
    "print(f'There are {len(documents)} documents/paragraphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('\\ufeffThe Project Gutenberg eBook of The History of Insects\\r\\n    \\r\\nThis ebook is for the use of anyone anywhere in the United States and\\r\\nmost other parts of the world at no cost and with almost no restrictions\\r\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\r\\nof the Project Gutenberg License included with this ebook or online\\r\\nat www.gutenberg.org. If you are not located in the United States,\\r\\nyou will have to check the laws of the country where you are located\\r\\nbefore using this eBook.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: DistilBertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder = SentenceTransformer('msmarco-distilbert-base-v4') # model that is pre-trained on an asymmetric semantic search task\n",
    "bi_encoder.max_seq_length = 256     # Truncate long documents to 256 tokens\n",
    "\n",
    "bi_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00,  4.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([70, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_embeddings = bi_encoder.encode(documents, convert_to_tensor=True, show_progress_bar=True) # document being encoded using .encode function\n",
    "\n",
    "document_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = 'What kind of butterflies are there?' # a natural language query that we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'corpus_id': 30, 'score': 0.5829142332077026},\n",
       " {'corpus_id': 29, 'score': 0.36111608147621155},\n",
       " {'corpus_id': 11, 'score': 0.33377891778945923}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_embedding = bi_encoder.encode(QUESTION, convert_to_tensor=True) # encoding the query using the bi-encoder\n",
    "\n",
    "hits = util.semantic_search(question_embedding, document_embeddings, top_k=3)[0] # number of documents to retrieve with the bi-encoder\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What kind of butterflies are there?\n",
      "\n",
      "Document 1 Cos_Sim 0.583:\n",
      "\n",
      "\n",
      "Of butterflies there are many kinds. How wonderful the various changes\n",
      "of this class of insects! The butterflies lay their eggs: from these\n",
      "hatch out worms or caterpillars, which change their skins several times,\n",
      "and, finally, become aureliae, chrysales, or silkworms, out of which\n",
      "come the beautiful butterflies.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.361:\n",
      "\n",
      "\n",
      "Of these flies, which are called by many Spindles, there are various\n",
      "species. They all have two very large eyes, covering the whole surface\n",
      "of the head. They fly very swiftly, and prey upon the wing, clearing the\n",
      "air of innumerable little flies. The great ones live about water, but\n",
      "the smaller are common among hedges, and about gardens.\n",
      "\n",
      "\n",
      "Document 3 Cos_Sim 0.334:\n",
      "\n",
      "There are two classes of crickets: viz. the field cricket, and the house\n",
      "cricket; the latter inhabits warm places, the holes of the hearth, &c.\n",
      "from whence we hear its notes, which are agreeable: it is said, that\n",
      "they are purchased by some, and kept in a kind of cage, for the sake of\n",
      "their music. Field crickets inhabit the meadows, and subsist on roots,\n",
      "&c. as does another species, called the mole cricket.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Question: {QUESTION}\\n')\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    \n",
    "    print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.03519178181886673, 'start': 27, 'end': 37, 'answer': 'many kinds'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(QUESTION, str(documents[hits[0]['corpus_id']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above system is called an open book Q/A system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Fine-Tuning the bi-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_qa = load_dataset('adversarial_qa', 'adversarialQA', split='train') # loading the dataset from HuggingFace directly\n",
    "\n",
    "# we will use the context and question fields of the dataset alone to fine-tune the bi-encoder system\n",
    "\n",
    "good_training_data = []\n",
    "bad_training_data = []\n",
    "\n",
    "last_example = None\n",
    "for example in training_qa:\n",
    "    if last_example and example['context'] != last_example['context']:\n",
    "        bad_training_data.append((example['question'], last_example['context'], 0.0))  #  give 0 similarity score for training i.e. neutral and not -1 as in that case the model would start to work against the context\n",
    "    \n",
    "    good_training_data.append((example['question'], example['context'], 1.0)) # question, context, label is 1 if should be matched together\n",
    "    last_example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2647)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(good_training_data), len(bad_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What letter designates what Ektachrome is designed for?',\n",
       " 'Some high-speed black-and-white films, such as Ilford Delta 3200 and Kodak T-MAX P3200, are marketed with film speeds in excess of their true ISO speed as determined using the ISO testing method. For example, the Ilford product is actually an ISO 1000 film, according to its data sheet. The manufacturers do not indicate that the 3200 number is an ISO rating on their packaging. Kodak and Fuji also marketed E6 films designed for pushing (hence the \"P\" prefix), such as Ektachrome P800/1600 and Fujichrome P1600, both with a base speed of ISO 400.',\n",
       " 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_training_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What film beside Ektachrome and Fujichorme is designed for pushing?',\n",
       " 'The Weston Cadet (model 852 introduced in 1949), Direct Reading (model 853 introduced 1954) and Master III (models 737 and S141.3 introduced in 1956) were the first in their line of exposure meters to switch and utilize the meanwhile established ASA scale instead. Other models used the original Weston scale up until ca. 1955. The company continued to publish Weston film ratings after 1955, but while their recommended values often differed slightly from the ASA film speeds found on film boxes, these newer Weston values were based on the ASA system and had to be converted for use with older Weston meters by subtracting 1/3 exposure stop as per Weston\\'s recommendation. Vice versa, \"old\" Weston film speed ratings could be converted into \"new\" Westons and the ASA scale by adding the same amount, that is, a film rating of 100 Weston (up to 1955) corresponded with 125 ASA (as per ASA PH2.5-1954 and before). This conversion was not necessary on Weston meters manufactured and Weston film ratings published since 1956 due to their inherent use of the ASA system; however the changes of the ASA PH2.5-1960 revision may be taken into account when comparing with newer ASA or ISO values.',\n",
       " 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_training_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(42)  # seed our upcoming sample\n",
    "\n",
    "sampled_training_data = sample(good_training_data, 500) + sample(bad_training_data, 500)\n",
    "\n",
    "shuffle(sampled_training_data)  # shuffle our data around\n",
    "\n",
    "training_index = int(.8 * len(sampled_training_data))  # Get an 80/20 train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': '',\n",
       " 'texts': ('What changed after the eigth century?',\n",
       "  'There is disagreement about the origin of the term, but general consensus that \"cardinalis\" from the word cardo (meaning \\'pivot\\' or \\'hinge\\') was first used in late antiquity to designate a bishop or priest who was incorporated into a church for which he had not originally been ordained. In Rome the first persons to be called cardinals were the deacons of the seven regions of the city at the beginning of the 6th century, when the word began to mean “principal,” “eminent,” or \"superior.\" The name was also given to the senior priest in each of the \"title\" churches (the parish churches) of Rome and to the bishops of the seven sees surrounding the city. By the 8th century the Roman cardinals constituted a privileged class among the Roman clergy. They took part in the administration of the church of Rome and in the papal liturgy. By decree of a synod of 769, only a cardinal was eligible to become pope. In 1059, during the pontificate of Nicholas II, cardinals were given the right to elect the pope under the Papal Bull In nomine Domini. For a time this power was assigned exclusively to the cardinal bishops, but the Third Lateran Council in 1179 gave back the right to the whole body of cardinals. Cardinals were granted the privilege of wearing the red hat by Pope Innocent IV in 1244.'),\n",
       " 'label': 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples = [InputExample(texts=t[:2], label=t[2]) for t in sampled_training_data[:training_index]] # Define the training examples\n",
    "\n",
    "train_examples[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_examples, shuffle=True, batch_size=32,\n",
    "    collate_fn=bi_encoder.smart_batching_collate\n",
    "    )  # A data loader is the object that specifically shuffles/grabs batches of data from a Dataset\n",
    "\n",
    "train_loss = losses.CosineSimilarityLoss(bi_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(question_batch, context_batch), labels = next(iter(train_dataloader))  # get a sample batch of data\n",
    "\n",
    "question_batch['input_ids'].shape, context_batch['input_ids'].shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation data, sentences1 and sentences2 are lists of questions and context respectively and scores are 0 or 1\n",
    "sentences1, sentences2, scores = zip(*sampled_training_data[training_index:])\n",
    "\n",
    "# evaluator will evaluate embedding closeness\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': np.float64(0.5021223579927213),\n",
       " 'spearman_cosine': np.float64(0.5044913287672261)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator) # a higher initial value is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mniketgirdhar2004\u001b[0m (\u001b[33mniketgirdhar2004-vit-chennai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/nt/Downloads/transformers/codes/bert/wandb/run-20250628_004159-0h7ws3qq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers/runs/0h7ws3qq' target=\"_blank\">checkpoints/model</a></strong> to <a href='https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers' target=\"_blank\">https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers/runs/0h7ws3qq' target=\"_blank\">https://wandb.ai/niketgirdhar2004-vit-chennai/sentence-transformers/runs/0h7ws3qq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 01:19, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Cosine</th>\n",
       "      <th>Spearman Cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>0.504838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.502689</td>\n",
       "      <td>0.505011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model using the fit method\n",
    "bi_encoder.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)], \n",
    "    output_path='ir/results',\n",
    "    epochs=2, \n",
    "    evaluator=evaluator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pearson_cosine': np.float64(0.5026890378632383),\n",
       " 'spearman_cosine': np.float64(0.5050109764878448)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_encoder.evaluate(evaluator) # not a huge jump in performance with 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_bi_encoder = SentenceTransformer('ir/results') # loading fine-tuned IR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What kind of butterflies are there?\n",
      "\n",
      "Document 1 Cos_Sim 0.584:\n",
      "\n",
      "\n",
      "Of butterflies there are many kinds. How wonderful the various changes\n",
      "of this class of insects! The butterflies lay their eggs: from these\n",
      "hatch out worms or caterpillars, which change their skins several times,\n",
      "and, finally, become aureliae, chrysales, or silkworms, out of which\n",
      "come the beautiful butterflies.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.363:\n",
      "\n",
      "\n",
      "Of these flies, which are called by many Spindles, there are various\n",
      "species. They all have two very large eyes, covering the whole surface\n",
      "of the head. They fly very swiftly, and prey upon the wing, clearing the\n",
      "air of innumerable little flies. The great ones live about water, but\n",
      "the smaller are common among hedges, and about gardens.\n",
      "\n",
      "\n",
      "Document 3 Cos_Sim 0.334:\n",
      "\n",
      "There are two classes of crickets: viz. the field cricket, and the house\n",
      "cricket; the latter inhabits warm places, the holes of the hearth, &c.\n",
      "from whence we hear its notes, which are agreeable: it is said, that\n",
      "they are purchased by some, and kept in a kind of cage, for the sake of\n",
      "their music. Field crickets inhabit the meadows, and subsist on roots,\n",
      "&c. as does another species, called the mole cricket.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_embeddings = finetuned_bi_encoder.encode(documents, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "question_embedding = finetuned_bi_encoder.encode(QUESTION, convert_to_tensor=True)\n",
    "\n",
    "# Get document hits\n",
    "hits = util.semantic_search(question_embedding, document_embeddings, top_k=3)[0]\n",
    "\n",
    "print(f'Question: {QUESTION}\\n')\n",
    "\n",
    "for i, hit in enumerate(hits):\n",
    "    \n",
    "    print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very minute change as fine--tuning has less data and less no. of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gutenberg_to_documents(gutenberg_url, bi_encoder):\n",
    "    text = urlopen(gutenberg_url).read().decode()\n",
    "    documents = np.array(list(filter(lambda x: len(x) > 100, text.split('\\r\\n\\r\\n'))))\n",
    "    print(f'There are {len(documents)} documents/paragraphs')\n",
    "    return documents, bi_encoder.encode(documents)\n",
    "\n",
    "def retrieve_relevant_documents(bi_encoder, query, documents, document_embeddings, hits=3):\n",
    "    query_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    hits = util.semantic_search(query_embedding, document_embeddings, top_k=hits)[0]\n",
    "\n",
    "    for i, hit in enumerate(hits):\n",
    "        print(f'Document {i + 1} Cos_Sim {hit[\"score\"]:.3f}:\\n\\n{documents[hit[\"corpus_id\"]]}')\n",
    "        print('\\n')\n",
    "    print(f\"Answer from Top Document: {nlp(query, str(documents[hits[0]['corpus_id']]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1396 documents/paragraphs\n"
     ]
    }
   ],
   "source": [
    "banks_to_bassoon_documents, banks_to_bassoon_embeddings = gutenberg_to_documents(\n",
    "    'https://www.gutenberg.org/cache/epub/27480/pg27480.txt', finetuned_bi_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Cos_Sim 0.754:\n",
      "\n",
      "BANSHEE (Irish _bean sidhe_; Gaelic _ban sith_, \"woman of the fairies\"), a\n",
      "supernatural being in Irish and general Celtic folklore, whose mournful\n",
      "screaming, or \"keening,\" at night is held to foretell the death of some\n",
      "member of the household visited. In Ireland legends of the banshee belong\n",
      "more particularly to certain families in whose records periodic visits from\n",
      "the spirit are chronicled. A like ghostly informer figures in Brittany\n",
      "folklore. The Irish banshee is held to be the distinction only of families\n",
      "of pure Milesian descent. The Welsh have the banshee under the name _gwrach\n",
      "y Rhibyn_ (witch of Rhibyn). Sir Walter Scott mentions a belief in the\n",
      "banshee as existing in the highlands of Scotland (_Demonology and\n",
      "Witchcraft_, p. 351). A Welsh death-portent often confused with the gwrach\n",
      "y Rhibyn and banshee is the _cyhyraeth_, the groaning spirit.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.324:\n",
      "\n",
      "BANNU, a town and district of British India, in the Derajat division of the\n",
      "North-West Frontier Province. The town (also called Edwardesabad and\n",
      "Dhulipnagar) lies in the north-west corner of the district, in the valley\n",
      "of the Kurram river. Pop. (1901) 14,300. It forms the base for all punitive\n",
      "expeditions to the Tochi Valley and Waziri frontier.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer from Top Document: {'score': 0.044728297740221024, 'start': 76, 'end': 94, 'answer': 'supernatural being'}\n"
     ]
    }
   ],
   "source": [
    "retrieve_relevant_documents(finetuned_bi_encoder,\n",
    "    'What is a banshee?', banks_to_bassoon_documents, banks_to_bassoon_embeddings, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 Cos_Sim 0.797:\n",
      "\n",
      "[3] The date 1876 is taken as being that when the Imperial Bank of Germany\n",
      "came into full operation.\n",
      "\n",
      "\n",
      "Document 2 Cos_Sim 0.573:\n",
      "\n",
      "Similar banks had been established in Middelburg, (March 28th, 1616), in\n",
      "Hamburg (1619) and in Rotterdam (February 9th, 1635). Of these the Bank of\n",
      "Hamburg carried on much the largest business and survived the longest. It\n",
      "was not till the 15th of February 1873 that its existence was closed by the\n",
      "act of the German parliament which decreed that Germany should possess a\n",
      "gold standard, and thus removed those conditions of the local medium of\n",
      "exchange--silver coins of very different intrinsic values--whose\n",
      "circulation had provided an ample field for the operations of the bank. The\n",
      "business of the Bank of Hamburg had been conducted in absolute accordance\n",
      "with the regulations under which it was founded.\n",
      "\n",
      "\n",
      "Answer from Top Document: {'score': 0.18934372067451477, 'start': 13, 'end': 17, 'answer': '1876'}\n"
     ]
    }
   ],
   "source": [
    "retrieve_relevant_documents(finetuned_bi_encoder,\n",
    "    'When was the Imperial Bank of Germany founded?', banks_to_bassoon_documents, banks_to_bassoon_embeddings, 2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
