# transformers

Flow:

- [Introduction to Attention and Language Models](introduction.md)
- [Transformer Artchitecture and attention usage for processing text](how_transformers_use_attention.md)
- [Transfer Learning](transfer_learning.md)
- [Understanding BERT](bert.md)
- [Understanding Pretraining and Fine-Tuning BERT](bert_pretrain_finetune.md)
- [Understanding the derivative architectures of BERT](derivatives_of_BERT.md)
