# transformers

Flow:

- [Introduction to Attention and Language Models](introduction.md)
- [Transformer Artchitecture and attention usage for processing text](how_transformers_use_attention.md)
- [Transfer Learning](transfer_learning.md)
- [Understanding BERT](bert.md)
- [BERT architecture in play using Python](codes/bert.ipynb)
- [Understanding Pretraining and Fine-Tuning BERT](bert_pretrain_finetune.md)
- [Pretraining and Fine-Tuning BERT in play using Python](codes/pretrain_finetune_bert.ipynb)
- [Understanding the derivative architectures of BERT](derivatives_of_BERT.md)
- [Implementing derivative architectures using Python](codes/bert_derivatives.ipynb)