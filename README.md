# Transformers

Flow:

- [Introduction to Attention and Language Models](introduction.md)
- [Transformer Artchitecture and attention usage for processing text](how_transformers_use_attention.md)
- [Transfer Learning](transfer_learning.md)
- **BERT**
    - [Understanding BERT](bert.md)
    - [Understanding Pretraining and Fine-Tuning BERT](bert_pretrain_finetune.md)
    - [Understanding the derivative architectures of BERT](derivatives_of_BERT.md)
    - **Fine-Tuning BERT**
        - [BERT for Sequence Classification](bert_for_seq_classification.md)
        - [BERT for Token Classification](bert_for_token_classification.md)
        - [BERT for Question Answering](bert_for_question_answer.md)
- **GPT**
    - [Understaing GPT](gpt.md)